## Задание 1:

Реализуйте класс ```OneIndexedList```, который имитирует поведение списка, использующего индексацию начинающуюся с 1 (а не с 0, как в стандартном списке). Используйте магические методы init, setitem, getitem

```python
a = OneIndexedList([1,2,3])
a[1]
>>> 1
```

NB!: 
При инициализации класса без аргумента ```OneIndexedList()```
класс должен использовать пустой список по умолчанию, поддерживающий такую индексацию

Подсказка:
[] or items

Пример:

```python
a = OneIndexedList()
a.items.append(0)
a[1]

>>> 0
```

Потестируйте валидность программы на случайных списках, не берите ```[1,2,3,4]```


## Задание 2:

Вам необходимо написать скрипт, в котором реализован класс ```FileReader()```

Конструктор этого класса принимает один параметр: путь до файла на диске. 

В классе ```FileReader()``` должен быть реализован метод ```read()```, возвращающий строку - содержимое файла, путь к которому был указан при создании экземпляра класса, а так же метод write, который записывает некоторое содержимое в файл. 

Python модуль должен быть написан таким образом, чтобы импорт класса ```FileReader()``` из него не вызвал ошибок. Например, при написании реализации метода read, вам нужно учитывать случай, когда при инициализации был передан путь к несуществующему файлу. Требуется обработать возникающее при этом исключение ```FileNotFoundError``` и вернуть из метода ```read()``` пустую строку.

Также в классе должен реализован метод ```count()```, который возвращает количество строк и слов в файле (для токенизации используйте ```NLTK```), а также записывает информацию в соответствующие атрибуты ```line_count``` и ```word_count```.

Кроме того в классе необходимо переопределять следующие магические методы:
a) ```__add__()```: склеивает содержимое двух файлов, записывает в текущую директорию, возвращает объект класса FileReader
b) ```__str__()```: выводит путь до файла (или же использовать ```__repr__()```)

Базовый пример:
```python
from solution import FileReader
reader = FileReader('file_doesnt_exist.txt')
text = reader.read()
text
>>> ''
with open('some_file.txt', 'w') as file:
     file.write('some text')

reader = FileReader('some_file.txt')
text = reader.read()
text
>>> 'some text'

type(reader)
>>> <class 'solution.FileReader'>
```


## Задание 3:

В этом задании вам необходимо реализовать свой униграммный морфологический анализатор. В классе ```UnigramMorphAnalyzer()``` должны быть реализованы следующие методы:

 * ```train()```: считывает слова из размеченного корпуса и накапливает частеречную статистику в соответствии с  окончаниями слов (4, 3, 2, 1 последних символа)

Частеречная статистика по окончаниям, если в наборе данных всего два слова ```[кровать, спать]``` должна иметь следующий вид:

```json
{
     "ь": 
          {"NOUN": 1, 
           "VERB": 1},
     "ть": 
          {"NOUN": 1, 
           "VERB": 1},
     "ать":
          {"NOUN": 1, 
           "VERB": 1},
     "вать":
          {"NOUN": 1},
     "пать":
          {"VERB": 1}
 }
 ```
 
 * ```predict()```: выводит список вероятностей различных частей речи для данного токена 
 
 * ```save()```: сохраняет модель с помощью библиотеки ```pickle```

 * ```load()```: загружает модель
 
 e) При вызове  ```UnigramMorphAnalyzer[‘ending’]``` должна выводиться частеречная статистика по указанному окончанию
 
 * ```eval()```: должна выводить точность анализатора на тестовых данных open corpora (для загрузки датасета используете библиотеку ```Corus``` https://nbviewer.jupyter.org/github/natasha/corus/blob/master/docs.ipynb#load_corpora)
(Разбейте заранее данные на train-test в пропорции 0.8 / 0.2 без перемешивания)


```bash
wget http://opencorpora.org/files/export/annot/annot.opcorpora.xml.byfile.zip
pip install tqdm, corus
```

```python
from corus import load_corpora
import tqdm

path = 'annot.opcorpora.xml.byfile.zip'
records = load_corpora(path)

with open('pos_data.txt', 'w', encoding='utf8') as f:
    for rec in tqdm.tqdm(records):
        for par in rec.pars:
            for sent in par.sents:
                for token in sent.tokens:
                    f.write(f'{token.text} {token.forms[0].grams[0]}\n')
```
