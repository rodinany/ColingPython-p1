## Задание: собрать собственный новостной корпус.

Для этого вам нужно:

* Найти источник для корпуса: журнал, газету, интернет-издание (Занесите в нашу Гугл-таблицу в графу HW7 название и ссылку на выбранный источник. У каждого он должен быть свой, уникальный.

* Спарсить новости (как минимум, за последний календарный год) с помощью ```requests```, ```bs4``` и ```re```. Хранить их нужно будет в ```CSV``` или ```JSON``` формате (на ваше усмотрение). Для каждой новости нужно хранить её дату, рубрику, ссылку и собственно саму новость. Можно добавить ещё и другую мета информацию. За неё добавим баллов сверху :)

После того как соберете свой корпус, проведите извлечение именованных сущностей с помощью ```Natasha```.
Для каждой рубрики посмотрите на распределение частот и представителей этих сущностей.
Готовый анализ представьте в виде jupyter notebook. Скрипт на парсинг сайта лучше оформить в виде ```.py``` (по PEP8, с использованием аргументов и кэширования при необходимости)

Корпус на GitHub грузить не надо. Залейте его на google/yandex/etc drive и прикрепите ссылку в README.md ветки